{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de datos\n",
    "## Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy as sp\n",
    "import math\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gzip\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from unidecode import unidecode\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, BooleanType\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import udf\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from pyspark.sql.functions import regexp_replace, to_date, trim, when, expr, concat, lit, col\n",
    "from pyspark.sql.types import StringType, DateType\n",
    "\n",
    "# Importar funciones necesarias\n",
    "from pyspark.sql.functions import col, to_date, weekofyear,year, month, dayofmonth, sum\n",
    "from pyspark.sql.functions import count, coalesce, sum as spark_sum\n",
    "from pyspark.sql.functions import regexp_replace, col, when, explode_outer,lit, to_timestamp,regexp_extract,lower,split\n",
    "from pyspark.sql.functions import format_number\n",
    "from pyspark.sql.types import IntegerType,FloatType\n",
    "# Puedes obtener estadísticas específicas para una columna\n",
    "from pyspark.sql.functions import mean, min, max\n",
    "from pyspark.sql.functions import approx_count_distinct\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import log1p\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de Datos  e Inicio del Clúster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nspark = SparkSession.builder     .appName(\"MLops_Steam_etl\")     .config(\"spark.executor.heartbeatInterval\", \"60s\")     .config(\"spark.network.timeout\", \"600s\")     .getOrCreate()\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder.appName(\"MLops_Steam_etl\").getOrCreate()\n",
    "\"\"\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MLops_Steam_etl\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"60s\") \\\n",
    "    .config(\"spark.network.timeout\", \"600s\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SparkSession.builder.appName(\"MLops_Steam_etl\").getOrCreate().stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-BAETS3I:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MLops_Steam_etl</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x15fec8574c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo Parquet\n",
    "steam_games = spark.read.parquet(\"../datasets/raw/steam_games_parquet\")\n",
    "user_reviews = spark.read.parquet(\"../datasets/raw/user_reviews_parquet\")\n",
    "users_items = spark.read.parquet(\"../datasets/raw/users_items_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros : 120445 Cantidad de las Columnas : 13\n",
      "Cantidad de registros : 59305 Cantidad de las Columnas : 9\n",
      "Cantidad de registros : 5153209 Cantidad de las Columnas : 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de registros :\", steam_games.count(), \"Cantidad de las Columnas :\", len(steam_games.columns))\n",
    "print(\"Cantidad de registros :\", user_reviews.count(), \"Cantidad de las Columnas :\", len(user_reviews.columns))\n",
    "print(\"Cantidad de registros :\", users_items.count(), \"Cantidad de las Columnas :\", len(users_items.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Definir la función para limpiar y formatear los nombres de las columnas\n",
    "def limpiar_nombres_columnas(df):\n",
    "    def limpiar_nombre(nombre):\n",
    "        nombre = re.sub(r'\\W+', '_', nombre)\n",
    "        nombre = unidecode(nombre)\n",
    "        nombre = nombre.lower()\n",
    "        return nombre\n",
    "    \n",
    "    nuevos_nombres = [limpiar_nombre(col) for col in df.columns]\n",
    "    \n",
    "    for viejo, nuevo in zip(df.columns, nuevos_nombres):\n",
    "        df = df.withColumnRenamed(viejo, nuevo)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Definir la función para tratar filas con valores nulos o vacíos\n",
    "def t_filas_nulos(df, columnas_a_eliminar=None, columna_filtro=None, eliminar_filas_vacias=False):\n",
    "    # Eliminar columnas si se proporcionan\n",
    "    if columnas_a_eliminar:\n",
    "        df = df.drop(*columnas_a_eliminar)\n",
    "    \n",
    "    # Filtrar registros nulos o vacíos en la columna especificada, si se proporciona\n",
    "    if columna_filtro and eliminar_filas_vacias:\n",
    "        df = df.filter(col(columna_filtro).isNotNull() & (col(columna_filtro) != \"\"))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Volver a aplicar la función de limpieza de nombres de columnas\n",
    "steam_games = limpiar_nombres_columnas(steam_games)\n",
    "user_reviews = limpiar_nombres_columnas(user_reviews)\n",
    "users_items = limpiar_nombres_columnas(users_items)\n",
    "\n",
    "# game_id debería ser la columna filtro y los nulos deberían clasificarse como \"Unknown\"\n",
    "steam_games = t_filas_nulos(steam_games, columnas_a_eliminar=[\"publisher\", \"title\", \"url\", \"tags_str\", \"reviews_url\", \"specs_str\", \"early_access\"], columna_filtro=\"game_id\", eliminar_filas_vacias=True)\n",
    "user_reviews = t_filas_nulos(user_reviews, columnas_a_eliminar=[\"user_url\", \"last_edited\", \"funny\", \"helpful\"], columna_filtro=\"item_id\", eliminar_filas_vacias=True)\n",
    "users_items = t_filas_nulos(users_items, columnas_a_eliminar=[\"user_url\", \"user_id\"], columna_filtro=\"steam_id\", eliminar_filas_vacias=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de Modelos json `steam_games.json.gz`, `user_reviews.json.gz` y  `users_items.json.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games = steam_games.withColumn(\n",
    "    \"price\",\n",
    "    when(steam_games[\"price\"].isin(\"\", \"Free\", \"Free Demo\", \"Free HITMAN™ Holiday Pack\", \"Free Mod\", \"Free Movie\", \"Free To Play\", \"Free to Play\", \"Free to Try\", \"Free to Use\", \"Install Now\", \"Install Theme\", \"Play Now\", \"Play WARMACHINE: Tactics Demo\", \"Play for Free!\", \"Play the Demo\", \"Third-party\"), -1.0)\n",
    "    .otherwise(regexp_extract(steam_games[\"price\"], r'\\d+(\\.\\d+)?', 0).cast(\"float\"))\n",
    ")\n",
    "\n",
    "# Tratar los valores en la columna 'release_date'\n",
    "steam_games_transformed = steam_games.withColumn(\n",
    "    \"release_date\",\n",
    "    when(\n",
    "        (steam_games[\"release_date\"] == \"\") | \n",
    "        (steam_games[\"release_date\"] == '\"\"\"Soon\"\"\"') | \n",
    "        (steam_games[\"release_date\"].rlike('[^\\d-]')), \n",
    "        '1970-01-01'\n",
    "    )\n",
    "    .otherwise(steam_games[\"release_date\"])\n",
    ")\n",
    "\n",
    "\n",
    "# Extraer los años de la columna 'release_date' y crear la columna 'year'\n",
    "steam_games_transformed = steam_games_transformed.withColumn(\n",
    "    \"year\",\n",
    "    when(\n",
    "        (steam_games_transformed[\"release_date\"] != \"\") & (steam_games_transformed[\"release_date\"].rlike(r\"(\\d{4})\")),\n",
    "        regexp_extract(steam_games_transformed[\"release_date\"], r\"(\\d{4})\", 1).cast(IntegerType())\n",
    "    )\n",
    "    .otherwise(\n",
    "        when(\n",
    "            (steam_games_transformed[\"release_date\"].like(\"%soon%\") | steam_games_transformed[\"release_date\"].like(\"%Soon%\")),\n",
    "            \"TBD\"\n",
    "        )\n",
    "        .otherwise(\"Unknown\")\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Convertir la columna 'year' a tipo entero\n",
    "steam_games_transformed = steam_games_transformed.withColumn(\"year\", when(steam_games_transformed[\"year\"] != \"TBD\", steam_games_transformed[\"year\"].cast(IntegerType())).otherwise(-1))\n",
    "\n",
    "# Convertir la columna 'release_date' a tipo fecha\n",
    "steam_games_transformed = steam_games_transformed.withColumn(\"release_date\", col(\"release_date\").cast(DateType()))\n",
    "# 1. Usa explode para convertir la lista en filas adicionales\n",
    "df_exploded = steam_games_transformed.select(\"genres_str\", explode(split(\"genres_str\", \",\")).alias(\"genre\"))\n",
    "\n",
    "# 2. Puedes realizar más transformaciones si es necesario\n",
    "# Por ejemplo, si quieres agregar alguna lógica específica o limpieza de datos\n",
    "# Puedes realizar operaciones como trim, regexp_replace, etc.\n",
    "df_exploded = df_exploded.withColumn(\"genre\", lower(regexp_replace(trim(col(\"genre\")), \"[^a-zA-Z0-9_]\", \"\")))\n",
    "\n",
    "# 3. Reemplazar cadenas vacías en la columna 'genre' por 'Unknown'\n",
    "df_exploded = df_exploded.withColumn(\"genre\", when(col(\"genre\") == \"\", \"Unknown\").otherwise(col(\"genre\")))\n",
    "\n",
    "# 4. Actualizar los valores en la tabla steam_games_transformed\n",
    "steam_games_transformed = steam_games_transformed.join(df_exploded, on=\"genres_str\")\n",
    "steam_games_transformed = steam_games_transformed.withColumn(\"genres_str\", col(\"genre\")).drop(\"genre\")\n",
    "# Tratar la columna 'developer'\n",
    "steam_games_transformed = steam_games_transformed.withColumn(\"developer\", when(steam_games_transformed[\"developer\"].isNull() | (steam_games_transformed[\"developer\"] == \"\"), \"Unknown\").otherwise(steam_games_transformed[\"developer\"]))\n",
    "steam_games_transformed = steam_games_transformed.withColumn(\"app_name\", when(col(\"app_name\").isin(\"\", \"null\", \"NULL\", \"Null\", \"nil\", \"NaN\", \"NA\"), \"Unknown\").otherwise(col(\"app_name\")))\n",
    "steam_games_transformed = steam_games_transformed.dropDuplicates(['app_name', 'release_date', 'price', 'game_id', 'developer', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para tratar la columna 'recommend'\n",
    "def transform_recommend_column(df):\n",
    "    df_transformed = df.withColumn(\n",
    "        \"recommend\",\n",
    "        when(df[\"recommend\"] == True, 1)\n",
    "        .otherwise(when(df[\"recommend\"] == False, 0))\n",
    "    ).withColumn(\"recommend\", col(\"recommend\").cast(IntegerType()))  # Convertir a tipo entero\n",
    "    return df_transformed\n",
    "user_reviews_transformed = transform_recommend_column(user_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtén el año actual\n",
    "current_year = datetime.now().year\n",
    "\n",
    "# Define el formato de fecha que parece tener el campo 'posted'\n",
    "date_format = 'MMM d, yyyy.'\n",
    "\n",
    "# Limpia y estandariza el campo 'posted' utilizando expresiones regulares\n",
    "user_reviews_transformed = user_reviews_transformed.withColumn(\n",
    "    \"clean_posted\",\n",
    "    regexp_replace(\"posted\", r'Posted\\s*', '')  # Elimina 'Posted'\n",
    ")\n",
    "\n",
    "# Elimina espacios en blanco adicionales\n",
    "user_reviews_transformed = user_reviews_transformed.withColumn(\n",
    "    \"clean_posted\",\n",
    "    trim(user_reviews_transformed[\"clean_posted\"]).alias(\"clean_posted\")\n",
    ")\n",
    "\n",
    "# Agrega el año actual a las fechas que no tienen año\n",
    "user_reviews_transformed = user_reviews_transformed.withColumn(\n",
    "    \"clean_posted\",\n",
    "    when(user_reviews_transformed[\"clean_posted\"].contains(\",\"), user_reviews_transformed[\"clean_posted\"]).otherwise(expr('concat(clean_posted, \", {}\")'.format(current_year)))\n",
    ")\n",
    "\n",
    "# Elimina el punto intermedio y agrega un punto al final\n",
    "user_reviews_transformed = user_reviews_transformed.withColumn(\n",
    "    \"clean_date\",\n",
    "    trim(concat(regexp_replace(\"clean_posted\", r'\\.,', ','), lit('.')))\n",
    ")\n",
    "\n",
    "# Convierte el campo 'clean_date' a formato de fecha utilizando to_date\n",
    "user_reviews_transformed = user_reviews_transformed.withColumn(\n",
    "    \"posted_date\",\n",
    "    to_date(\"clean_date\", date_format).cast(DateType()).alias(\"posted_date\")\n",
    ")\n",
    "\n",
    "# Reemplaza las cadenas nulas o vacías en la columna 'review' con 'Unknown'\n",
    "user_reviews_transformed = user_reviews_transformed.withColumn(\"review\", when((col(\"review\").isNull()) | (col(\"review\") == \"\"), \"Unknown\").otherwise(col(\"review\")))\n",
    "\n",
    "# Muestra el DataFrame resultante\n",
    "#user_reviews_transformed.show(truncate=False)\n",
    "# Eliminar las columnas mencionadas\n",
    "user_reviews_transformed = user_reviews_transformed.drop(\"posted\", \"clean_posted\", \"clean_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+---------+--------------------+-----------+\n",
      "|            user_id|item_id|recommend|              review|posted_date|\n",
      "+-------------------+-------+---------+--------------------+-----------+\n",
      "|kitchenappliancewow| 322330|        1|Don't Starve Toge...| 2024-08-19|\n",
      "|kitchenappliancewow| 413150|        1|Stardew Valley is...| 2024-08-19|\n",
      "|  kittenwithmittens| 287290|        0|Cooperative play ...| 2015-02-25|\n",
      "|  76561198068660878| 301520|        1|                good| 2024-08-23|\n",
      "|  76561198068660878|    620|        1|  sooooooo gooooood!| 2024-08-13|\n",
      "|  76561198068660878| 212680|        1|  This game is great| 2015-11-09|\n",
      "|  76561198068660878| 218230|        1|           good game| 2014-10-14|\n",
      "|  76561198065171294|   4000|        1|                 ...| 2024-02-12|\n",
      "|  76561198068160202|    440|        1|             10 star| 2014-02-27|\n",
      "|       coronelcross| 312990|        1|super entretenido...| 2014-08-21|\n",
      "+-------------------+-------+---------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_reviews_transformed.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convierte la columna 'items_count' a entero\n",
    "users_items_transformed = users_items.withColumn(\"items_count\", col(\"items_count\").cast(\"int\"))\n",
    "\n",
    "# Convierte la columna 'playtime_forever' a entero\n",
    "users_items_transformed = users_items_transformed.withColumn(\"playtime_forever\", col(\"playtime_forever\").cast(\"int\"))\n",
    "\n",
    "# Convierte la columna 'playtime_2weeks' a entero\n",
    "users_items_transformed = users_items_transformed.withColumn(\"playtime_2weeks\", col(\"playtime_2weeks\").cast(\"int\"))\n",
    "\n",
    "users_items_transformed = users_items_transformed.dropDuplicates(['item_id'])\n",
    "#user_reviews_transformed = t_filas_nulos(user_reviews_transformed, columnas_a_eliminar=[\"user_url\"], eliminar_filas_vacias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------------+-----+-------+---------+----+\n",
      "|genres_str|app_name|release_date|price|game_id|developer|year|\n",
      "+----------+--------+------------+-----+-------+---------+----+\n",
      "|         0|       0|           0|    0|      0|        0|   0|\n",
      "+----------+--------+------------+-----+-------+---------+----+\n",
      "\n",
      "+-------+-------+---------+------+-----------+\n",
      "|user_id|item_id|recommend|review|posted_date|\n",
      "+-------+-------+---------+------+-----------+\n",
      "|      0|      0|        0|     0|          0|\n",
      "+-------+-------+---------+------+-----------+\n",
      "\n",
      "+-----------+--------+-------+---------+----------------+---------------+\n",
      "|items_count|steam_id|item_id|item_name|playtime_forever|playtime_2weeks|\n",
      "+-----------+--------+-------+---------+----------------+---------------+\n",
      "|          0|       0|      0|        0|               0|              0|\n",
      "+-----------+--------+-------+---------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the function to count null or empty values for each column\n",
    "def count_null_values(df):\n",
    "    return df.select(\n",
    "        *[sum(coalesce(col(c) == \"\", col(c).isNull()).cast(\"int\")).alias(c) for c in df.columns]\n",
    "    )\n",
    "\n",
    "# Clean and count null values for each DataFrame\n",
    "#steam_games = limpiar_nombres_columnas(steam_games)\n",
    "valores_vacios_por_columna_steam = count_null_values(steam_games_transformed)\n",
    "valores_vacios_por_columna_steam.show()\n",
    "\n",
    "#user_reviews = limpiar_nombres_columnas(user_reviews)\n",
    "valores_vacios_por_columna_reviews = count_null_values(user_reviews_transformed)\n",
    "valores_vacios_por_columna_reviews.show()\n",
    "\n",
    "#users_items = limpiar_nombres_columnas(users_items)\n",
    "valores_vacios_por_columna_items = count_null_values(users_items_transformed)\n",
    "valores_vacios_por_columna_items.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado Registros post ETL con PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros : 32132 Cantidad de las Columnas : 7\n",
      "Cantidad de registros : 59305 Cantidad de las Columnas : 5\n",
      "Cantidad de registros : 10978 Cantidad de las Columnas : 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de registros :\", steam_games_transformed.count(), \"Cantidad de las Columnas :\", len(steam_games_transformed.columns))\n",
    "print(\"Cantidad de registros :\", user_reviews_transformed.count(), \"Cantidad de las Columnas :\", len(user_reviews_transformed.columns))\n",
    "print(\"Cantidad de registros :\", users_items_transformed.count(), \"Cantidad de las Columnas :\", len(users_items_transformed.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenación Registros post ETL con PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir steam_games_transformed con user_reviews_transformed\n",
    "joined_df = steam_games_transformed.join(user_reviews_transformed, steam_games_transformed.game_id == user_reviews_transformed.item_id, \"inner\")\n",
    "\n",
    "# Unir el resultado anterior con users_items_transformed usando item_id\n",
    "final_etl = joined_df.join(users_items_transformed, joined_df.item_id == users_items_transformed.item_id, \"inner\")\n",
    "\n",
    "# Seleccionar las columnas relevantes después de la unión\n",
    "final_etl = final_etl.select(\n",
    "    steam_games_transformed[\"genres_str\"],\n",
    "    steam_games_transformed[\"app_name\"],\n",
    "    steam_games_transformed[\"release_date\"],\n",
    "    steam_games_transformed[\"price\"],\n",
    "    steam_games_transformed[\"game_id\"],\n",
    "    steam_games_transformed[\"developer\"],\n",
    "    steam_games_transformed[\"year\"],\n",
    "    user_reviews_transformed[\"user_id\"],\n",
    "    user_reviews_transformed[\"item_id\"].alias(\"user_reviews_item_id\"),\n",
    "    user_reviews_transformed[\"recommend\"],\n",
    "    user_reviews_transformed[\"review\"],\n",
    "    user_reviews_transformed[\"posted_date\"],\n",
    "    users_items_transformed[\"items_count\"],\n",
    "    users_items_transformed[\"steam_id\"],\n",
    "    users_items_transformed[\"item_id\"].alias(\"users_items_item_id\"),\n",
    "    users_items_transformed[\"item_name\"],\n",
    "    users_items_transformed[\"playtime_forever\"],\n",
    "    users_items_transformed[\"playtime_2weeks\"]\n",
    "    # Agrega otras columnas que desees incluir en el resultado\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+------------+-----------------+-------+---------+----+-----------------+--------------------+---------+--------------------+-----------+-----------+-----------------+-------------------+--------------+----------------+---------------+\n",
      "|genres_str|      app_name|release_date|            price|game_id|developer|year|          user_id|user_reviews_item_id|recommend|              review|posted_date|items_count|         steam_id|users_items_item_id|     item_name|playtime_forever|playtime_2weeks|\n",
      "+----------+--------------+------------+-----------------+-------+---------+----+-----------------+--------------------+---------+--------------------+-----------+-----------+-----------------+-------------------+--------------+----------------+---------------+\n",
      "|    action|Counter-Strike|  2000-11-01|9.989999771118164|     10|    Valve|2000|             mizi|                  10|        1|        og cs is god| 2015-05-23|         11|76561197971591953|                 10|Counter-Strike|               0|              0|\n",
      "|    action|Counter-Strike|  2000-11-01|9.989999771118164|     10|    Valve|2000|       nottynotty|                  10|        1|         GoODGAmP!!!| 2024-04-01|         11|76561197971591953|                 10|Counter-Strike|               0|              0|\n",
      "|    action|Counter-Strike|  2000-11-01|9.989999771118164|     10|    Valve|2000|76561198122904623|                  10|        1|Best game ever ca...| 2015-05-30|         11|76561197971591953|                 10|Counter-Strike|               0|              0|\n",
      "|    action|Counter-Strike|  2000-11-01|9.989999771118164|     10|    Valve|2000|76561198107235245|                  10|        1|echamos unas part...| 2013-11-26|         11|76561197971591953|                 10|Counter-Strike|               0|              0|\n",
      "|    action|Counter-Strike|  2000-11-01|9.989999771118164|     10|    Valve|2000|           t1e57o|                  10|        1|           dA-beSt<3| 2013-10-06|         11|76561197971591953|                 10|Counter-Strike|               0|              0|\n",
      "+----------+--------------+------------+-----------------+-------+---------+----+-----------------+--------------------+---------+--------------------+-----------+-----------+-----------------+-------------------+--------------+----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_etl.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- genres_str: string (nullable = false)\n",
      " |-- app_name: string (nullable = true)\n",
      " |-- release_date: date (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- game_id: string (nullable = true)\n",
      " |-- developer: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user_reviews_item_id: string (nullable = true)\n",
      " |-- recommend: integer (nullable = true)\n",
      " |-- review: string (nullable = true)\n",
      " |-- posted_date: date (nullable = true)\n",
      " |-- items_count: integer (nullable = true)\n",
      " |-- steam_id: string (nullable = true)\n",
      " |-- users_items_item_id: string (nullable = true)\n",
      " |-- item_name: string (nullable = true)\n",
      " |-- playtime_forever: integer (nullable = true)\n",
      " |-- playtime_2weeks: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_etl.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_etl = spark.read.csv(\"../datasets/processed/dataset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversión Pyspark a Pandas, por estrategía  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_etl.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47675 entries, 0 to 47674\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   genres_str            47675 non-null  object \n",
      " 1   app_name              47675 non-null  object \n",
      " 2   release_date          47675 non-null  object \n",
      " 3   price                 47675 non-null  float64\n",
      " 4   game_id               47675 non-null  object \n",
      " 5   developer             47675 non-null  object \n",
      " 6   year                  47675 non-null  int32  \n",
      " 7   user_id               47675 non-null  object \n",
      " 8   user_reviews_item_id  47675 non-null  object \n",
      " 9   recommend             47675 non-null  int32  \n",
      " 10  review                47675 non-null  object \n",
      " 11  posted_date           47675 non-null  object \n",
      " 12  items_count           47675 non-null  int32  \n",
      " 13  steam_id              47675 non-null  object \n",
      " 14  users_items_item_id   47675 non-null  object \n",
      " 15  item_name             47675 non-null  object \n",
      " 16  playtime_forever      47675 non-null  int32  \n",
      " 17  playtime_2weeks       47675 non-null  int32  \n",
      "dtypes: float64(1), int32(5), object(12)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../datasets/processed/datasets.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of training sets:\n",
      "X_train: (28605, 17)\n",
      "y_train: (28605,)\n",
      "\n",
      "Shapes of testing sets:\n",
      "X_test: (19070, 17)\n",
      "y_test: (19070,)\n"
     ]
    }
   ],
   "source": [
    "# Definir la variable objetivo \"recommend\" codificada\n",
    "y = df['recommend']\n",
    "\n",
    "# Seleccionar el resto de las columnas (variables predictoras) y eliminar la columna\n",
    "X = df.drop(columns=['recommend'])\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Verificar las formas de los conjuntos resultantes\n",
    "print(\"Shapes of training sets:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"\\nShapes of testing sets:\")\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar la Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../datasets/processed/'\n",
    "X_train.to_csv(filename + 'X_train.csv', sep=',', index=False)\n",
    "y_train.to_csv(filename + 'y_train.csv', sep=',', index=False)\n",
    "X_test.to_csv(filename + 'X_test.csv', sep=',', index=False)\n",
    "y_test.to_csv(filename + 'y_test.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evstack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
